{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Copy of Plant_Disease_Classification Project",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moaabid/Plant-Leaf-Disease-Classifcation-Using-Deep-Learning-and-Flutter/blob/main/Plant_Disease_Classification_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR70hF5jcSaT"
      },
      "source": [
        "# **Plant_Leaf_Disease_Classification using Tensorflow**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfQ6xkc-FlMS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "froM4kB7cq4z"
      },
      "source": [
        "Abstract: \n",
        "\n",
        "Plant Disease is one of the main threat to global food security. The main loss of food is due to infected plants,which reflexively reduce the production rate. Disease in plant mostly on the leaves affects the quality and quantity of the plant products. The most common diagnosis is primarily performed by examining the plant leaf for the presence of visual symptoms. Lot of us have less knowledge in plant and its disease . So, it's hard to identify disease with our lesser knowledge. \n",
        "\n",
        "In this technological era we can easily identify what disease is affected in the plant. This project provide an software solution which automatically classify the plant Disease. Deep learning techniques have been very successful in image classification problems. This project uses Deep Convolutional Neural Network (CNN) to detect plant diseases from images of plant leaves and accurately classify them and small neural network is trained using a publicly available data set of 54000 images, which achieves an accuracy of 98%. This neural network is built using Keras to running on top of the deep learning framework called Tensor Flow. Overall,This project uses deep learning technique to classify the plant leaf disease and by integrating with mobile phone to makes smartphone-assisted disease classification.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RVsYZLEpEWs"
      },
      "source": [
        "# Step 1 : Import Libraries\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUCEcRdhnyWn"
      },
      "source": [
        "Below I have imported some libraries.\n",
        " \n",
        "\n",
        "1.   Tensorflow                     \n",
        "          - Tensorflow is a Machine learning Framework used to Design,Build and Train deep learning Model.Here we imported tensorflow library to do make Computational,Understanding,Discovery,Prediction and Creating models.\n",
        "2.   numpy\n",
        "          - Numpy is an python library which provides High performance multidimensional array and tools for working with this array.\n",
        "3.   matplotlib.pylot\n",
        "          - Matplotlib library works like an MATLAB.Which helps us to plot Graph, Histogram,Barplot etc,.\n",
        "4.   Tensorflow Hub\n",
        "          - TensorFlow Hub is a library for the publication, discovery, and consumption of reusable parts of machine learning models. A module is a self-contained piece of a TensorFlow graph, along with its weights and assets, that can be reused across different tasks in a process known as transfer learning.\n",
        "5.   Tensorflow_datasets\n",
        "         - Tensorflow_datasets contains collection of datasets.\n",
        "6.   layers from Tensorflow keras\n",
        "         - Layers library availabel in tensorflow keras helps us to create layers in deep learning model.\n",
        "\n",
        "7.   Logging\n",
        "         - Logging library helps us to log error messages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxwCQNZWIL8y"
      },
      "source": [
        "import tensorflow as tf                                                                 #import tensorflow library\n",
        "!pip install tfds-nightly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivDUkUNdINH2"
      },
      "source": [
        "import os\n",
        "\n",
        "import numpy as np                                                                      #import numpy library\n",
        "import matplotlib.pyplot as plt                                                         #import matplotlib library \n",
        "\n",
        "import tensorflow_hub as hub                                                            #import tensorflow_hub\n",
        "import tensorflow_datasets as tfds                                                      #import tenorflow_datasets\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "from tensorflow.keras import layers                                                     #import layers from tensorflow.keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"Hub version: \", hub.__version__)\n",
        "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU3IAZ02G6VA"
      },
      "source": [
        "import logging                              #import logging.\n",
        "logger = tf.get_logger()                    #Here I'm calling tensorflow logger function and assigned in the logger variable.\n",
        "logger.setLevel(logging.ERROR)              #Logs message with level ERROR on this logger."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amfzqn1Oo7Om"
      },
      "source": [
        "# Step 2 : Download the Plant_leaf_Dataset  using TensorFlow Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z93vvAdGxDMD"
      },
      "source": [
        "In the cell below i download the Diseases affected Plant_leaf dataset using TensorFlow Datasets. (https://www.tensorflow.org/datasets/catalog/plant_village). This dataset is only split into a TRAINING set.Therefore using `tfds.splits` to split this training set into to a `training_set` and a `validation_set` and done a `[70, 30]` split such that 70 corresponds to the `training_set` and 30 to the `validation_set`. Then load the `plant_village` dataset using `tfds.load`. In the `tfds.load` function i uses the parameters such as `split`, `with_info`, `as_supervised`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXiJjX0jfx1o"
      },
      "source": [
        "(training_set, validation_set,test_set), dataset_info = tfds.load(\n",
        "    'plant_village',                                               #loading plant_village_Dataset\n",
        "    split=['train[80%:]', 'train[80%:90%]', 'train[90%:]'],        #spliting 80 to training set,10% to validation set and 10% test_set.\n",
        "    with_info=True,                                                #setting with_info True so that we can get dataset information.\n",
        "    as_supervised=True,                                            #By setting as_supervised value True the tf.data.dataset will return 2 tuples(input,label)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0p1sOEHf0JF"
      },
      "source": [
        "# Step 3 : Print Information about the Plant Dataset\n",
        "\n",
        "Downloading the dataset is completed, Using the dataset info to print the number of classes in the dataset, and also coded to count how many images in the training and validation sets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrIUV3V0xDL_"
      },
      "source": [
        "num_classes = dataset_info.features['label'].num_classes                          #Storing number of classes in num_classes variable.\n",
        "\n",
        "num_training_examples = 0                                                         #Assign 0 to num_training_examples\n",
        "num_validation_examples = 0                                                       #Assign 0 to num_validation_examples\n",
        "num_test_examples = 0\n",
        "\n",
        "for example in training_set:\n",
        "  num_training_examples += 1                                                      #Using for loop getting no of training images\n",
        "\n",
        "for example in validation_set:\n",
        "  num_validation_examples += 1                                                    #Using for loop getting no of Validation images\n",
        "\n",
        "for example in test_set:\n",
        "  num_test_examples += 1  \n",
        "\n",
        "print('Total Number of Classes: {}'.format(num_classes))                          #printing Total number of classes\n",
        "print('Total Number of Training Images: {}'.format(num_training_examples))        #printing Total Number of Training Images\n",
        "print('Total Number of Validation Images: {}'.format(num_validation_examples))    #printing Total Number of Validation Images\n",
        "print('Total Number of Test Images: {} \\n'.format(num_test_examples))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlFZ_hwjCLgS"
      },
      "source": [
        "In the below cell checking image shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4lDPkn2cpWZ"
      },
      "source": [
        "for i, example in enumerate(training_set.take(5)):\n",
        "  print('Image {} shape: {} label: {}'.format(i+1, example[0].shape, example[1]))     #Here printing 5 different image shapes and it's corresponding labels."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSAycb6Dq8Gt"
      },
      "source": [
        "image = np.array([[[1], [2]], [[3], [4]]]) \n",
        "tf.image.random_flip_up_down(image, None).numpy().tolist() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbgpD3E6gM2P"
      },
      "source": [
        "# Step 4 : Reformat Images and Create Batches\n",
        "\n",
        "In the cell below, I create a function that reformats all images to the resolution expected by MobileNet v2 (224, 224) and normalizes them. The function take in an `image` and a `label` as arguments and return the new `image` and corresponding `label`. Then creating training and validation batches of size `32`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we_ftzQxNf7e"
      },
      "source": [
        "IMAGE_RES = 224                                                                                                   #Assigning Image resolution as 224\n",
        "\n",
        "def format_image(image, label):\n",
        "  image = tf.image.resize(image, (IMAGE_RES, IMAGE_RES))/255.0                                                    #In this function i'm resizing images to IMAGE_RES and converting to binary value\n",
        "  return image, label                                                                                             \n",
        "                                                                                       #Assigning Batchsize as 32"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyE-ZuZXxAgH"
      },
      "source": [
        "BATCH_SIZE = 32 #@param {type:\"integer\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUEaZVEgxDmC"
      },
      "source": [
        "train_batches = training_set.shuffle(num_training_examples//4).map(format_image).batch(BATCH_SIZE).prefetch(1)    #Formating and shuffling the images\n",
        "\n",
        "validation_batches = validation_set.map(format_image).batch(BATCH_SIZE).prefetch(1)                               #Formating validation images\n",
        "test_batches = test_set.map(format_image).batch(1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEuJb8py4rcx"
      },
      "source": [
        "for i, example in enumerate(train_batches.take(5)):\n",
        "  print('Image {} shape: {}'.format(i+1, example[0].shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W91ETTSpdMk_"
      },
      "source": [
        "for image_batch, label_batch in train_batches.take(1):\n",
        "  pass\n",
        "\n",
        "image_batch.shape\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzV457OXreQP"
      },
      "source": [
        "#  Step 5 : Simple Transfer Learning with TensorFlow Hub\n",
        "\n",
        "Using TensorFlow Hub to do Transfer Learning.Transfer learning reuse parts of an already trained model and change the final layer, or several layers, of the model, and then retrain those layers on our own dataset.\n",
        "\n",
        "### Creating a Feature Extractor\n",
        "In the cell below creating a `feature_extractor` using MobileNet v2.The partial model from TensorFlow Hub (without the final classification layer) is called a feature vector.[TensorFlow Hub documentation](https://tfhub.dev/s?module-type=image-feature-vector&q=tf2) to see list of available feature vectors and Finally, creating a `feature_extractor` by using `hub.KerasLayer` with the correct `input_shape` parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wB030nezBwI"
      },
      "source": [
        "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"  #mobilenet v2 url without final classfication layer\n",
        "feature_extractor = hub.KerasLayer(URL,\n",
        "                                   input_shape=(IMAGE_RES, IMAGE_RES, 3))   #Extracting layers from the url with corresponding Image resolution"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtFmF7A5E4tk"
      },
      "source": [
        "### Freezing the Pre-Trained Model\n",
        "\n",
        "In the cell below freezing the variables in the feature extractor layer, so that the training only modifies the final classifier layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg5ar6rcE4H-"
      },
      "source": [
        "feature_extractor.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPVeouTksO9q"
      },
      "source": [
        "### Attaching a classification head\n",
        "\n",
        "In the cell below creating a `tf.keras.Sequential` model, and adding the pre-trained model and the new classification layer.The classification layer must have the same number of classes as plant dataset. Finally printing a summary of the Sequential model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGcY27fY1q3Q"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "  feature_extractor,                          #pre-trained model\n",
        "  layers.Dense(num_classes)                   #new classifcation Dense layers with number of classes in the plant dataset\n",
        "])\n",
        "\n",
        "model.summary()                               #summary of the sequential model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHbXQqIquFxQ"
      },
      "source": [
        "# Step 6 : Train the model\n",
        "\n",
        "In the cell bellow training the model, by first calling `compile` and then followed by `fit`. Training the model for only 8 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n0Wb9ylKd8R"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',                                                             #Using adam as an optimizer\n",
        "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),         #Using SparseCategoricalCrossentropy to calculate loss\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 5                                                                      #Assigning epochs as 5\n",
        "\n",
        "history = model.fit(train_batches,                                              #Here i'm training train dataset with epochs 10 and validating with validation dataset\n",
        "                    epochs=EPOCHS,\n",
        "                    validation_data=validation_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLxTcprUqJaq"
      },
      "source": [
        "# Step 7 : Plot Training and Validation Graphs\n",
        "\n",
        "In the cell below, plotting the training and validation accuracy/loss graphs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d28dhbFpr98b"
      },
      "source": [
        "acc = history.history['accuracy']                                                 #Getting accuracy history\n",
        "val_acc = history.history['val_accuracy']                                         #Getting validation accuracy history\n",
        "\n",
        "loss = history.history['loss']                                                    #Getting loss history\n",
        "val_loss = history.history['val_loss']                                            #Gettting validaiton loss history \n",
        "\n",
        "epochs_range = range(EPOCHS)                                                      #Getting Epochs range\n",
        "\n",
        "plt.figure(figsize=(8, 8))                                                        #figure size width=8 and height=8\n",
        "plt.subplot(1, 2, 1)                                                              #subplot Row=1 Column=2 \n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')                            #ploting Training accuracy\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')                      #ploting validation accuracy\n",
        "plt.legend(loc='lower right')                                                     #label in lower right\n",
        "plt.title('Training and Validation Accuracy')                                     #Title\n",
        "\n",
        "plt.subplot(1, 2, 2)                                                              #subplot Row=1 Column=2\n",
        "plt.plot(epochs_range, loss, label='Training Loss')                               #ploting Training loss\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')                         #ploting Validation loss\n",
        "plt.legend(loc='upper right')                                                     #label in upper right\n",
        "plt.title('Training and Validation Loss')                                         #Title\n",
        "plt.show()                                                                        #show function used to show figure"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb__ZN8uFn-D"
      },
      "source": [
        "# Step 8 : Check Predictions\n",
        "\n",
        "In the cell below getting the label names from the dataset info and convert them into a NumPy array. Printing the array to make sure the correct label names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Zvg2i0fzJu"
      },
      "source": [
        "class_names = np.array(dataset_info.features['label'].names)              #Getting label names from dataset info and converted to numpy\n",
        "\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Olg6MsNGJTL"
      },
      "source": [
        "### Creating an Image Batch and Make Predictions\n",
        "\n",
        "In the cell below, Using the `next()` function to create an `image_batch` and its corresponding `label_batch`. Converting both the `image_batch` and `label_batch` to numpy arrays using the `.numpy()` method. Then using the `.predict()` method to run the image batch through the model and make predictions. Then using the `np.argmax()` function to get the indices of the best prediction for each image. Finally converting the indices of the best predictions to class names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCLVCpEjJ_VP"
      },
      "source": [
        "#creating image batch and label batch using next function\n",
        "image_batch, label_batch = next(iter(train_batches))         \n",
        "\n",
        "#converting image batch to numoy array using numpy function\n",
        "image_batch = image_batch.numpy()                              \n",
        "\n",
        "#converting label batch to numoy array using numpy function\n",
        "label_batch = label_batch.numpy()\n",
        "\n",
        "#Using predict function and run the image batch through the model and make predictions\n",
        "predicted_batch = model.predict(image_batch)\n",
        "predicted_batch = tf.squeeze(predicted_batch).numpy()\n",
        "\n",
        "#Using mp.argmax function to get indices of the best prediction for each image\n",
        "predicted_ids = np.argmax(predicted_batch, axis=-1)\n",
        "\n",
        "#converting indices to class names\n",
        "predicted_class_names = class_names[predicted_ids]\n",
        "\n",
        "print(predicted_class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkGbZxl9GZs-"
      },
      "source": [
        "### Printing True Labels and Predicted Indices\n",
        "\n",
        "In the cell below, printing the true labels and the indices of predicted labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nL9IhOmGI5dJ"
      },
      "source": [
        "print(\"Labels:           \", label_batch)          \n",
        "print(\"Predicted labels: \", predicted_ids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJDyzEfYuFcW"
      },
      "source": [
        "# Step 9 : Plot Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wC_AYRJU9NQe"
      },
      "source": [
        "plt.figure(figsize=(10,9))                                                    #figure width=10 Height =9   \n",
        "\n",
        "for n in range(10):                                                           #Here plotting 10 predicted model\n",
        "  plt.subplot(5,2,n+1)  \n",
        "  plt.subplots_adjust(hspace = .3)\n",
        "  plt.imshow(image_batch[n])\n",
        "  color = \"White\" if predicted_ids[n] == label_batch[n] else \"red\"\n",
        "  plt.title(predicted_class_names[n].title(), color=color)\n",
        "  plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (blue: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_gcHysFBp3q"
      },
      "source": [
        "# Step 10 : Export Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "012HNsN0B0iY"
      },
      "source": [
        "PLANT_DISEASE_SAVED_MODEL = \"exp_saved_model\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTlnGgEUB5Gh"
      },
      "source": [
        "tf.saved_model.save(model, PLANT_DISEASE_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpbFWPicCBdX"
      },
      "source": [
        "%%bash -s $PLANT_DISEASE_SAVED_MODEL\n",
        "saved_model_cli show --dir $1 --tag_set serve --signature_def serving_default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2wzDrmoCINH"
      },
      "source": [
        "loaded = tf.saved_model.load(PLANT_DISEASE_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uzIMBfd6CKcP"
      },
      "source": [
        "print(list(loaded.signatures.keys()))\n",
        "infer = loaded.signatures[\"serving_default\"]\n",
        "print(infer.structured_input_signature)\n",
        "print(infer.structured_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tyLkJahyf2Y"
      },
      "source": [
        "# Step 11:  Convert using TFLite's Converter\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFs8K8RQypIb"
      },
      "source": [
        "Loading the TFLiteConverter with the SavedModel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_CwvueCH1b3E"
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(PLANT_DISEASE_SAVED_MODEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rl51xIbtyteh"
      },
      "source": [
        "### Post-training quantization\n",
        "The simplest form of post-training quantization quantizes weights from floating point to 8-bits of precision. This technique is enabled as an option in the TensorFlow Lite converter. At inference, weights are converted from 8-bits of precision to floating point and computed using floating-point kernels. This conversion is done once and cached to reduce latency.\n",
        "\n",
        "To further improve latency, hybrid operators dynamically quantize activations to 8-bits and perform computations with 8-bit weights and activations. This optimization provides latencies close to fully fixed-point inference. However, the outputs are still stored using floating point, so that the speedup with hybrid ops is less than a full fixed-point computation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lccECsZiyxid"
      },
      "source": [
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tz8_RMq9y1Wj"
      },
      "source": [
        "### Post-training integer quantization\n",
        "We can get further latency improvements, reductions in peak memory usage, and access to integer only hardware accelerators by making sure all model math is quantized. To do this, we need to measure the dynamic range of activations and inputs with a representative data set. You can simply create an input data generator and provide it to our converter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4haD47Iy4Hd"
      },
      "source": [
        "def representative_data_gen():\n",
        "  for input_value, _ in test_batches.take(100):\n",
        "    yield [input_value]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ADqn4BQy6br"
      },
      "source": [
        "converter.representative_dataset = representative_data_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAy9fH-hy8Vh"
      },
      "source": [
        "The resulting model will be fully quantized but still take float input and output for convenience.\n",
        "\n",
        "Ops that do not have quantized implementations will automatically be left in floating point. This allows conversion to occur smoothly but may restrict deployment to accelerators that support float. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJg8ne8iy-qf"
      },
      "source": [
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_M_BiKRzBJ0"
      },
      "source": [
        "### Finally convert the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gdPlmfpzDym"
      },
      "source": [
        "tflite_model = converter.convert()\n",
        "tflite_model_file = 'converted_model.tflite'\n",
        "\n",
        "with open(tflite_model_file, \"wb\") as f:\n",
        "  f.write(tflite_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq3ufPpVzGbn"
      },
      "source": [
        "# Step 12 :Test the TFLite model using the Python Interpreter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMlSUOfrzPSI"
      },
      "source": [
        "# Load TFLite model and allocate tensors.\n",
        "  \n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvwzPGSzRND"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# Gather results for the randomly sampled test images\n",
        "predictions = []\n",
        "\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(10)):\n",
        "  interpreter.set_tensor(input_index, img)\n",
        "  interpreter.invoke()\n",
        "  predictions.append(interpreter.get_tensor(output_index))\n",
        "  \n",
        "  test_labels.append(label.numpy()[0])\n",
        "  test_imgs.append(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zSRdOQHzWAN",
        "cellView": "form"
      },
      "source": [
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "# class_names = class_names\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "    \n",
        "  img = np.squeeze(img)\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'green'\n",
        "  else:\n",
        "    color = 'red'\n",
        "  \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od2GyRuBzw2z",
        "cellView": "form"
      },
      "source": [
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "index = 4 #@param {type:\"slider\", min:0, max:9, step:1}\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(index, predictions, test_labels, test_imgs)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVDCt5S0z2L8"
      },
      "source": [
        "Download the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLV61KGyz1zP"
      },
      "source": [
        "\n",
        "labels = class_names\n",
        "with open('labels.txt', 'w') as f:\n",
        "  f.write('\\n'.join(labels))\n",
        "\n",
        "try:\n",
        "  from google.colab import files\n",
        "  files.download('converted_model.tflite')\n",
        "  files.download('labels.txt')\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}